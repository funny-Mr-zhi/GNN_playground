# 论文标题

Chain-of-Thought Prompting Elicits Reasoning in Large language Models

## 基本信息
- **作者**: Google Research, Brain Team
- **期刊/会议**: NIPS
- **年份**: 2022
- **引用数**: 26
- **代码**: 

## 背景与痛点

大型语言模型（LLMs）的性能随规模扩大而提升，但在算术、常识、符号推理等复杂任务中，单纯扩大模型规模的效果有限。传统方法存在两类局限：

* 基于推理步骤的微调方法需要大量高质量标注数据，成本高；
* 传统少样本提示（仅提供输入 - 输出示例）在推理任务中表现差，且随模型规模提升不明显。

为此，论文结合 “生成自然语言推理步骤” 和 “少样本提示” 的优势，提出思维链提示：在少样本示例中加入 “思维链（一系列中间推理步骤）”，引导模型生成类似推理过程，从而解锁其推理能力。

在少样本提示中，每个示例不仅包含 “输入 - 输出”，还包含中间思维链（即⟨输入，思维链，输出⟩三元组），引导模型在解答新问题时自动生成类似推理步骤。

## 核心贡献
1. 主要贡献点1：多余的计算能力用于分解多步骤问题。
2. 主要贡献点2：中间步骤提供更高的可解释性
3. 主要贡献点3：可用于解决推理问题，并超越微调方法
4. 主要贡献点4：大模型中应用很方便

## 方法概述
### 问题定义
- 输入：包含⟨问题，思维链，答案⟩三元组的少样本示例，以及新的测试问题。
- 输出：测试问题的答案，附带中间推理步骤（思维链）。
- 目标：使大型语言模型能够分解复杂问题，通过多步推理得到正确答案，提升在算术、常识、符号推理任务中的性能。

### 核心方法
- 关键思想：模拟人类解决复杂问题的思考过程，在提示中加入自然语言中间推理步骤，引导模型 “逐步思考” 后输出答案。
- 技术细节：思维链是一系列连贯的自然语言推理步骤（如 “先计算 A，再计算 B，最后合并结果”）。少样本示例构造：为每个任务手动设计 8 个左右包含思维链的示例（如数学题中详细写出计算步骤）。
- 算法流程：

## 实验分析
### 数据集
- 数据集名称和特点：算术推理：GSM8K（数学应用题）、SVAMP（结构多样的数学题）、ASDiv（多样化数学题）、AQuA（代数题）、MAWPS（数学题库）。CSQA（常识问答）、StrategyQA（多步策略推理）、Date Understanding（日期推理）、Sports Understanding（体育常识判断）、SayCan（机器人任务规划）。最后字母拼接（如 “Lady Gaga”→“ya”）、硬币翻转（跟踪硬币状态）。
- 实验设置：测试 GPT-3、LaMDA、PaLM 等模型（参数规模从 350M 到 540B），对比标准提示与思维链提示的性能，使用贪婪解码采样。

### 主要结果
- 性能对比表格
- 消融实验结果：“仅输出方程”“仅增加计算量”“推理步骤在答案后” 等变体性能远低于思维链提示，证明自然语言中间步骤的必要性。
- 可视化分析：图 2 显示 PaLM 540B 在 GSM8K 上的性能超越微调模型；图 4 证明思维链提示的效果随模型规模增长而显著提升。

## 优缺点分析
### 优点
- 方法的创新性
- 实验的充分性
- 结果的显著性

### 缺点
- 方法的局限性
- 实验的不足
- 可能的改进方向

## 启发和思考
- 对自己研究的启发
- 可能的扩展方向
- 实现的难点

## 相关工作
- 引用的重要论文
- 后续的相关工作
- 研究脉络梳理